package org.nandor.spark;

import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Timer;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.json.simple.JSONArray;
import org.json.simple.JSONObject;
import org.json.simple.parser.JSONParser;
import org.json.simple.parser.ParseException;

public class Testing{

	public static JSONObject readJson(String file){
		JSONParser parser = new JSONParser();
		JSONObject a = new JSONObject();
		try {
			a = (JSONObject) parser.parse(new FileReader(file));
		} catch (IOException | ParseException e) {
			e.printStackTrace();
		}
		return a;
	}
	
	public static void writeJson(String file,JSONObject json){
		FileWriter f;
		try {
			f = new FileWriter(file);
			f.write(json.toJSONString());
			f.flush();
			f.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	

	public static void main(String[] args) {
		
		//Timer
		
		Timer timer = new Timer();
		//timer.schedule(Methods.timerTask, 300, 600000);
		
		//Init
		Fog f = Methods.InitFog(15,0);//Cluster Count, Cloud Gw Count
	    //Fog f=Exporter.readJsonFog(readJson("C:/Users/Nandor/Documents/FogOfThings/Gateway Apps/spark-test/src/main/java/org/nandor/spark/deploy-W.json"));
		//writeJson("C:/Users/Nandor/Documents/FogOfThings/Gateway Apps/spark-test/src/main/java/org/nandor/spark/deploy-W.json",Exporter.writeJsonFog(f));
		 
	    //DisplayData(f);
		//Global Optimization
		Map<String,Float> data = Methods.GAGlobalStuff(f, 60, 200,true);//Fog, Generation Size, Generation Cunt

		//Clustering
		long start=System.currentTimeMillis();
		Methods.Clustering(f,1,6);
		Methods.ResourceAllocation(f);
		System.out.println("Clustering Time Elapsed: "+(System.currentTimeMillis()-start)/(float)1000);
		Methods.displayClsAndRes(f);
		
		//GA Cluster Stuff
		Map<String,Float> data2 = Methods.GAClusStuff(f, 60, 200,true);
		
		Methods.nandorsAlphaResourceAlloc(f);
		Map<String,Float> data3 = Methods.GAClusStuff(f, 60, 200,true);
		
		System.out.println("Global GA: "+data);
		System.out.println("Clust GA: "+data2);
		System.out.println("Clust GA-newAlloc: "+data3);
		/*//Exhaustive Cluster Stuff
		start=System.currentTimeMillis();
		Methods.ExhaustiveClusStuff(f);
		System.out.println("Time Elapsed: "+(System.currentTimeMillis()-start)/(float)1000);
		start=System.currentTimeMillis();*/
		
		//writeJson("C:/Users/Nandor/Documents/FogOfThings/Gateway Apps/spark-test/src/main/java/org/nandor/spark/deploy-W.json",Exporter.writeJsonFog(f));
		timer.cancel();
	}
	
}
